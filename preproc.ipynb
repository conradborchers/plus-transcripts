{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa1be646-22ce-4090-8097-f283e3f1cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb351d6-23ea-45da-98fd-d9d6340f6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p human-transcripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a25070-25d8-4802-a733-3447245d3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = glob.glob('matched_transcripts/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e635cb62-5120-4c74-893e-4b43e1a57f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pencil_transcript_to_df(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    file_name = f.split('/')[-1]\n",
    "    \n",
    "    entries = data['transcript']\n",
    "    rows = []\n",
    "    \n",
    "    for entry in entries:\n",
    "        text = entry.get('text', '')\n",
    "        start = entry.get('start')\n",
    "        end = entry.get('end')\n",
    "    \n",
    "        # Try to get speaker from entry\n",
    "        speaker = entry.get('speaker')\n",
    "    \n",
    "        # If not found, try to infer from first word's speaker\n",
    "        if speaker is None:\n",
    "            words = entry.get('words', [])\n",
    "            if words and 'speaker' in words[0]:\n",
    "                speaker = words[0]['speaker']\n",
    "            else:\n",
    "                speaker = \"UNKNOWN\"\n",
    "    \n",
    "        rows.append({\n",
    "            'file_name': file_name,\n",
    "            'speaker': speaker,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'text': text.strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23f68f21-29a3-4f3b-ac11-c1e5057b6903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3075/3075 [00:11<00:00, 263.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(fs):\n",
    "    df = pencil_transcript_to_df(f)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a094061-05a3-4e5d-83dd-263e80be7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pencil = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "197436c0-3c94-45f4-a887-072075028181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pencil.to_csv('exports/2025-05-08-pencil-transcripts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c62176c6-f878-46da-8d9d-dade1fd5f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisperx_transcript_to_df(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    file_name = path.split('/')[-1]\n",
    "    segments = data['whisperxTranscript']['whisper']['align']['segments']\n",
    "\n",
    "    rows = []\n",
    "    for seg in segments:\n",
    "        rows.append({\n",
    "            'file_name': file_name,\n",
    "            'speaker': seg.get('speaker', 'UNKNOWN'),\n",
    "            'start': seg['start'],\n",
    "            'end': seg['end'],\n",
    "            'text': seg['text'].strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0354904a-9a4b-4801-9c1e-bb121d091c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3075/3075 [00:11<00:00, 257.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(fs):\n",
    "    df = whisperx_transcript_to_df(f)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b28102ee-3d3c-4433-95bd-56c811ee9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whisperx = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ab1e1bd-153d-496b-b5ac-3cd85f9e81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whisperx.to_csv('exports/2025-05-08-whisperX-transcripts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82a30a5-5d19-49d2-8496-7816b49bc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(row, df_whisperx):\n",
    "    start, end = row['start'], row['end']\n",
    "\n",
    "    # Find overlaps\n",
    "    overlap = df_whisperx[\n",
    "        ((df_whisperx['start'] <= end) & (df_whisperx['end'] >= start))\n",
    "    ].copy()\n",
    "\n",
    "    if not overlap.empty:\n",
    "        # Choose the one with the most overlap\n",
    "        overlap['overlap'] = overlap.apply(\n",
    "            lambda r: min(end, r['end']) - max(start, r['start']), axis=1)\n",
    "        return overlap.sort_values('overlap', ascending=False).iloc[0]\n",
    "    else:\n",
    "        # Fallback: choose the closest in start time\n",
    "        closest_idx = (df_whisperx['start'] - start).abs().idxmin()\n",
    "        return df_whisperx.loc[closest_idx]\n",
    "\n",
    "def sample_and_fuzzy_match(df_pencil, df_whisperx, n=300):\n",
    "    # Step 1: Uniform sample from df_pencil\n",
    "    sampled_pencil = df_pencil.sample(n=n, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Find best match in df_whisperx\n",
    "    matched_whisperx = sampled_pencil.apply(lambda row: find_best_match(row, df_whisperx), axis=1)\n",
    "\n",
    "    # Step 3: Combine side-by-side\n",
    "    comparison_df = pd.concat(\n",
    "        [sampled_pencil.add_suffix('_pencil').reset_index(drop=True),\n",
    "         matched_whisperx.add_suffix('_whisperx').reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "    comparison_df = comparison_df.drop(columns=['file_name_whisperx']).rename(columns={'file_name_pencil': 'file_name'}).copy()\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f7931de-4e66-4321-b141-921243c68f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = sample_and_fuzzy_match(df_pencil, df_whisperx, n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3fd8400-5b22-42a1-aae5-0d97a4e54bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.to_csv('exports/2025-05-08-matched-snippets-1000-sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77603650-e57c-4c42-a44b-19361c8761ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
